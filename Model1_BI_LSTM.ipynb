{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-21T21:02:41.509980Z",
     "iopub.status.busy": "2025-12-21T21:02:41.509284Z",
     "iopub.status.idle": "2025-12-21T21:02:41.656354Z",
     "shell.execute_reply": "2025-12-21T21:02:41.655780Z",
     "shell.execute_reply.started": "2025-12-21T21:02:41.509948Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/tvsum50-video-summarization\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"georgelifinrell/tvsum50-video-summarization\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:02:43.878537Z",
     "iopub.status.busy": "2025-12-21T21:02:43.877783Z",
     "iopub.status.idle": "2025-12-21T21:02:43.882693Z",
     "shell.execute_reply": "2025-12-21T21:02:43.881938Z",
     "shell.execute_reply.started": "2025-12-21T21:02:43.878508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, applications\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, LSTM, Bidirectional, Dense, Layer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:02:51.572020Z",
     "iopub.status.busy": "2025-12-21T21:02:51.571528Z",
     "iopub.status.idle": "2025-12-21T21:02:51.576947Z",
     "shell.execute_reply": "2025-12-21T21:02:51.576187Z",
     "shell.execute_reply.started": "2025-12-21T21:02:51.571989Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "NEW_KAGGLE_ROOT = \"/kaggle/input/tvsum50-video-summarization\"\n",
    "TEST_VIDEO_ID = \"-esJrBWj2d8\" \n",
    "\n",
    "SKIP_FRAMES = 15\n",
    "TOP_K = 5\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "\n",
    "VIDEO_DIR = \"\" \n",
    "LABEL_FILE = \"ydata-tvsum50-anno.tsv\" \n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:02:54.809758Z",
     "iopub.status.busy": "2025-12-21T21:02:54.809261Z",
     "iopub.status.idle": "2025-12-21T21:02:54.815656Z",
     "shell.execute_reply": "2025-12-21T21:02:54.814990Z",
     "shell.execute_reply.started": "2025-12-21T21:02:54.809727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def setup_paths():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PATH VALIDATION\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    if not os.path.isdir(VIDEO_DIR):\n",
    "        print(f\"ERROR: VIDEO_DIR not found: {VIDEO_DIR}\")\n",
    "        return False\n",
    "    print(f\"Video directory: {VIDEO_DIR}\")\n",
    "\n",
    "    video_files = glob.glob(os.path.join(VIDEO_DIR, \"*.mp4\"))\n",
    "    if not video_files:\n",
    "        print(f\"ERROR: No .mp4 files in {VIDEO_DIR}\")\n",
    "        return False\n",
    "    print(f\"Found {len(video_files)} video files\")\n",
    "\n",
    "    if not os.path.isfile(LABEL_FILE):\n",
    "        print(f\"ERROR: Label file not found: {LABEL_FILE}\")\n",
    "        return False\n",
    "    print(f\"Annotation file: {os.path.basename(LABEL_FILE)}\")\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:03:08.614785Z",
     "iopub.status.busy": "2025-12-21T21:03:08.614216Z",
     "iopub.status.idle": "2025-12-21T21:03:08.623689Z",
     "shell.execute_reply": "2025-12-21T21:03:08.623085Z",
     "shell.execute_reply.started": "2025-12-21T21:03:08.614756Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_all_tsv_ids():\n",
    "    valid_ids = set()\n",
    "    try:\n",
    "        with open(LABEL_FILE, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 3:\n",
    "                    valid_ids.add(parts[0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading TSV: {e}\")\n",
    "    return valid_ids\n",
    "\n",
    "def get_manual_tvsum_labels(video_id, total_frames, valid_ids):\n",
    "    if video_id not in valid_ids:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(LABEL_FILE, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        user_scores = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            if parts[0] == video_id:\n",
    "                scores = np.array([float(s) for s in parts[2].split(',')])\n",
    "                user_scores.append(scores)\n",
    "\n",
    "        if not user_scores:\n",
    "            return None\n",
    "\n",
    "        avg_scores = np.mean(user_scores, axis=0)\n",
    "        gt_score = cv2.resize(avg_scores.reshape(1, -1), (total_frames, 1), \n",
    "                             interpolation=cv2.INTER_NEAREST)\n",
    "        gt_score = (gt_score - gt_score.min()) / (gt_score.max() - gt_score.min() + 1e-6)\n",
    "        return gt_score.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting labels for {video_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    original_frames = []\n",
    "    count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if count % SKIP_FRAMES == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            original_frames.append(frame_rgb)\n",
    "            frames.append(cv2.resize(frame_rgb, (224, 224)))\n",
    "        count += 1\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(frames), np.array(original_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:15:49.330641Z",
     "iopub.status.busy": "2025-12-21T21:15:49.329906Z",
     "iopub.status.idle": "2025-12-21T21:15:49.339963Z",
     "shell.execute_reply": "2025-12-21T21:15:49.339181Z",
     "shell.execute_reply.started": "2025-12-21T21:15:49.330610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    return applications.ResNet50(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "def extract_features(frames, model):\n",
    "    if len(frames) == 0:\n",
    "        return np.array([])\n",
    "    frames_pre = applications.resnet50.preprocess_input(frames.astype('float32'))\n",
    "    return model.predict(frames_pre, batch_size=32, verbose=0)\n",
    "\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "\n",
    "    def call(self, features):\n",
    "        score = tf.nn.tanh(self.W1(features))\n",
    "        return tf.nn.softmax(self.V(score), axis=1)\n",
    "\n",
    "class BiLSTMSummarizer(tf.keras.Model):\n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super(BiLSTMSummarizer, self).__init__()\n",
    "        self.lstm = Bidirectional(LSTM(hidden_dim, return_sequences=True))\n",
    "        self.attention = SelfAttention(64)\n",
    "        self.regressor = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        lstm_out = self.lstm(x)\n",
    "        att_weights = self.attention(lstm_out)\n",
    "        frame_scores = self.regressor(lstm_out)\n",
    "        return frame_scores * att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T21:46:01.462870Z",
     "iopub.status.busy": "2025-12-21T21:46:01.462134Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configuring Paths ---\n",
      "✅ Found Video Directory: /kaggle/input/tvsum50-video-summarization/video (50 videos)\n",
      "✅ Found Local Annotation File: /kaggle/input/tvsum50-video-summarization/data/ydata-tvsum50-anno.tsv\n",
      "\n",
      "=== Training Model 1 (Bi-LSTM) ===\n",
      "DEBUG: Label file contains 50 valid IDs.\n",
      "Train videos: 40, Val videos: 10\n",
      "Epoch 1/10 - train_loss: 0.1816, val_loss: 0.1837 (used 40 train / 10 val videos)\n",
      "✅ Best model updated (val_loss=0.1837)\n",
      "Epoch 2/10 - train_loss: 0.1806, val_loss: 0.1835 (used 40 train / 10 val videos)\n",
      "✅ Best model updated (val_loss=0.1835)\n",
      "Epoch 3/10 - train_loss: 0.1801, val_loss: 0.1835 (used 40 train / 10 val videos)\n",
      "Epoch 4/10 - train_loss: 0.1799, val_loss: 0.1836 (used 40 train / 10 val videos)\n",
      "Epoch 5/10 - train_loss: 0.1797, val_loss: 0.1832 (used 40 train / 10 val videos)\n",
      "✅ Best model updated (val_loss=0.1832)\n",
      "Epoch 6/10 - train_loss: 0.1795, val_loss: 0.1838 (used 40 train / 10 val videos)\n",
      "Epoch 7/10 - train_loss: 0.1793, val_loss: 0.1835 (used 40 train / 10 val videos)\n",
      "Epoch 8/10 - train_loss: 0.1792, val_loss: 0.1833 (used 40 train / 10 val videos)\n",
      "Epoch 9/10 - train_loss: 0.1791, val_loss: 0.1835 (used 40 train / 10 val videos)\n",
      "Epoch 10/10 - train_loss: 0.1791, val_loss: 0.1836 (used 40 train / 10 val videos)\n",
      "✅ Final Model 1 Saved as 'model1.weights.h5'\n",
      "\n",
      "=== Training Model 2 (Autoencoder) ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_supervised_tf(video_dir):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING MODEL 1: Bi-LSTM (Supervised)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    valid_ids = load_all_tsv_ids()\n",
    "    print(f\"Loaded {len(valid_ids)} video IDs from annotations\")\n",
    "\n",
    "    if len(valid_ids) == 0:\n",
    "        print(\"❌ No valid IDs found\")\n",
    "        return None, None\n",
    "\n",
    "    feat_model = build_feature_extractor()\n",
    "    model = BiLSTMSummarizer()\n",
    "    optimizer = optimizers.Adam(learning_rate=LR)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    video_files = glob.glob(os.path.join(video_dir, \"*.mp4\"))\n",
    "    print(f\"Training on {len(video_files)} videos for {EPOCHS} epochs\\n\")\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        count = 0\n",
    "        np.random.shuffle(video_files)\n",
    "\n",
    "        for v_path in video_files:\n",
    "            v_id = os.path.splitext(os.path.basename(v_path))[0]\n",
    "\n",
    "            if v_id not in valid_ids:\n",
    "                continue\n",
    "\n",
    "            frames, _ = preprocess_video(v_path)\n",
    "            if len(frames) == 0:\n",
    "                continue\n",
    "\n",
    "            labels = get_manual_tvsum_labels(v_id, len(frames), valid_ids)\n",
    "            if labels is None:\n",
    "                continue\n",
    "\n",
    "            feats = extract_features(frames, feat_model)\n",
    "            x = np.expand_dims(feats, axis=0)\n",
    "            y = np.expand_dims(labels, axis=0)[..., np.newaxis]\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                preds = model(x, training=True)\n",
    "                min_len = min(preds.shape[1], y.shape[1])\n",
    "                loss = mse(y[:, :min_len, :], preds[:, :min_len, :])\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "            total_loss += loss.numpy()\n",
    "            count += 1\n",
    "\n",
    "        if count > 0:\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss/count:.4f} | Videos: {count}\")\n",
    "        else:\n",
    "            print(\"❌ No matching videos found\")\n",
    "            break\n",
    "\n",
    "    model.save_weights(\"model1.weights.h5\")\n",
    "    print(f\"\\nModel saved: model1.weights.h5\")\n",
    "    return model, feat_model\n",
    "\n",
    "\n",
    "def visualize_keyframes(original_frames, indices, title):\n",
    "    \"\"\"Display keyframes\"\"\"\n",
    "    indices = sorted(indices)\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.suptitle(title, fontsize=16, fontweight='bold', y=1.05)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(1, len(indices), i + 1)\n",
    "        plt.imshow(original_frames[idx])\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Frame {idx}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if setup_paths():\n",
    "        # TRAIN\n",
    "        model1, feat_extractor = train_supervised_tf(VIDEO_DIR)\n",
    "\n",
    "        # TEST\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"TESTING ON: {TEST_VIDEO_ID}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        test_search = glob.glob(os.path.join(VIDEO_DIR, f\"*{TEST_VIDEO_ID}*\"))\n",
    "\n",
    "        if test_search:\n",
    "            test_path = test_search[0]\n",
    "            print(f\"Video: {os.path.basename(test_path)}\")\n",
    "\n",
    "            frames, orig_frames = preprocess_video(test_path)\n",
    "            print(f\"Extracted {len(frames)} frames (every {SKIP_FRAMES}th frame)\\n\")\n",
    "\n",
    "            # Model 1\n",
    "            if model1 and len(frames) > 0:\n",
    "                print(\"Model 1 (BiLSTM):\")\n",
    "                feats = extract_features(frames, feat_extractor)\n",
    "                x = np.expand_dims(feats, axis=0)\n",
    "                scores = model1.predict(x, verbose=0).flatten()\n",
    "                idx1 = scores.argsort()[-TOP_K:][::-1]\n",
    "                print(f\"  Keyframes: {sorted(idx1)}\")\n",
    "                visualize_keyframes(orig_frames, idx1, \"Model 1: BiLSTM\")\n",
    "\n",
    "        else:\n",
    "            print(f\"❌ Video not found: {TEST_VIDEO_ID}\")\n",
    "            all_videos = glob.glob(os.path.join(VIDEO_DIR, \"*.mp4\"))\n",
    "            print(f\"\\nAvailable videos ({len(all_videos)} total):\")\n",
    "            for v in all_videos[:10]:\n",
    "                print(f\"  - {os.path.splitext(os.path.basename(v))[0]}\")\n",
    "            if len(all_videos) > 10:\n",
    "                print(f\"  ... and {len(all_videos) - 10} more\")\n",
    "    else:\n",
    "        print(\"\\n❌ Setup failed - check paths above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7643666,
     "sourceId": 12137468,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
